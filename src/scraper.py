"""
è¯„è®ºæŠ“å–æ ¸å¿ƒæ¨¡å—
"""
import asyncio
import re
from typing import List, Dict, Any


# å…³é”®é€‰æ‹©å™¨ - åŸºäºå®é™…ç½‘ç«™ç»“æ„ï¼ˆOneNewBiteï¼‰
SELECTORS = {
    # é”šç‚¹ï¼šè¯„è®ºåŒºå®¹å™¨
    'COMMENT_CONTAINER': '#sidebar-comments-region',
    
    # Previous Comments æŒ‰é’® - æ ¹æ®ç”¨æˆ·æä¾›çš„å®é™…é€‰æ‹©å™¨
    'PREVIOUS_COMMENTS_BUTTON': '#sidebar-comments-region > div > div.comments-region > div > div.load-more-wrapper-previous > a',
    
    # More å±•å¼€é“¾æ¥ - åªé’ˆå¯¹è¯„è®ºå†…å®¹çš„å±•å¼€ï¼Œé¿å…ç‚¹å‡»å›¾ç‰‡å’Œå…¶ä»–å…ƒç´ 
    'EXPAND_MORE_LINKS': '#sidebar-comments-region .comment-body.mighty-wysiwyg-content.fr-view.wysiwyg-comment.long.is-truncated > a:has-text("more")',
    
    # æ›´é€šç”¨çš„ More é“¾æ¥é€‰æ‹©å™¨ä½œä¸ºå¤‡é€‰ - é™åˆ¶åœ¨è¯„è®ºåŒºåŸŸå†…
    'EXPAND_LINKS_FALLBACK': '#sidebar-comments-region a.more.text-color-grey-3-link:has-text("more")',
    
    # è¯„è®ºé¡¹ï¼ˆåœ¨å®¹å™¨å†…æŸ¥æ‰¾ï¼‰
    'COMMENT_ITEMS': 'li',  # å¿…é¡»åœ¨COMMENT_CONTAINERå†…ä½¿ç”¨
    
    # è¯„è®ºåŒºåŸŸé€‰æ‹©å™¨
    'COMMENTS_REGION': '.comments-region',
    'COMMENT_BODY_CONTAINER': '.comment-body-container',
    'COMMENT_BODY_TRUNCATED': '.comment-body.is-truncated'
}


async def get_expected_comment_count(page):
    """
    ä»è¯„è®ºå¤´éƒ¨è·å–æœŸæœ›çš„è¯„è®ºæ€»æ•°
    """
    try:
        # ä½¿ç”¨ç”¨æˆ·æä¾›çš„é€‰æ‹©å™¨
        header_selectors = [
            '#flyout-right-drawer-region > div.comments-sidebar-layout > div.comment-sidebar-header > div.comment-count',
            '#flyout-right-drawer-region > div.comments-sidebar-layout > div.comment-sidebar-header > h2',
            '.comment-count',
            '.comments-count'
        ]
        
        for selector in header_selectors:
            try:
                element = page.locator(selector).first
                if await element.count() > 0:
                    text = await element.text_content()
                    # å°è¯•æå–æ•°å­—
                    import re
                    numbers = re.findall(r'\d+', text or '')
                    if numbers:
                        count = int(numbers[0])
                        print(f"ğŸ“Š ä»è¯„è®ºå¤´éƒ¨è·å–åˆ°æœŸæœ›è¯„è®ºæ•°: {count}")
                        return count
            except:
                continue
        
        print("âš ï¸ æ— æ³•ä»è¯„è®ºå¤´éƒ¨è·å–è¯„è®ºæ•°é‡")
        return None
        
    except Exception as e:
        print(f"è·å–æœŸæœ›è¯„è®ºæ•°æ—¶å‡ºé”™: {e}")
        return None


async def debug_page_structure(page):
    """
    è°ƒè¯•ï¼šåˆ†æé¡µé¢ç»“æ„ï¼Œå¸®åŠ©ç¡®è®¤é€‰æ‹©å™¨
    """
    try:
        print("ğŸ” è°ƒè¯•: åˆ†æé¡µé¢ç»“æ„...")
        
        # è·å–æœŸæœ›çš„è¯„è®ºæ•°é‡
        expected_count = await get_expected_comment_count(page)
        
        # æ£€æŸ¥è¯„è®ºåŒºå®¹å™¨
        comment_region = page.locator('#sidebar-comments-region')
        if await comment_region.count() > 0:
            print("âœ… æ‰¾åˆ°è¯„è®ºåŒºå®¹å™¨")
            
            # æ£€æŸ¥ Previous Comments æŒ‰é’®
            previous_buttons = await page.locator(SELECTORS['PREVIOUS_COMMENTS_BUTTON']).count()
            print(f"ğŸ“„ Previous Comments æŒ‰é’®æ•°é‡: {previous_buttons}")
            
            # æ£€æŸ¥ More é“¾æ¥
            more_links_1 = await page.locator('a:has-text("more")').count()
            more_links_2 = await page.locator('a.more').count()
            print(f"ğŸ“„ More é“¾æ¥æ•°é‡ (æ–‡æœ¬åŒ¹é…): {more_links_1}")
            print(f"ğŸ“„ More é“¾æ¥æ•°é‡ (ç±»é€‰æ‹©å™¨): {more_links_2}")
            
            # æ£€æŸ¥è¯„è®ºé¡¹
            comment_items = await comment_region.locator('li').count()
            print(f"ğŸ“„ è¯„è®ºé¡¹æ•°é‡: {comment_items}")
            
            # æ¯”è¾ƒæœŸæœ›æ•°é‡å’Œå®é™…æ•°é‡
            if expected_count:
                print(f"ğŸ“Š æœŸæœ›è¯„è®ºæ•°: {expected_count}, å½“å‰è¯„è®ºé¡¹æ•°: {comment_items}")
                if comment_items < expected_count:
                    print(f"âš ï¸ å¯èƒ½è¿˜æœ‰ {expected_count - comment_items} ä¸ªè¯„è®ºæœªåŠ è½½")
            
        else:
            print("âŒ æœªæ‰¾åˆ°è¯„è®ºåŒºå®¹å™¨")
            
    except Exception as e:
        print(f"è°ƒè¯•è¿‡ç¨‹å‡ºé”™: {e}")


async def load_all_previous_comments(page, config):
    """
    é€’å½’åŠ è½½æ‰€æœ‰å±‚çº§çš„ Previous Comments
    åŒ…æ‹¬æ ¹çº§åˆ«å’ŒåµŒå¥—åœ¨å›å¤ä¸­çš„ Previous Comments
    """
    total_loaded = 0
    max_iterations = 10  # é˜²æ­¢æ— é™å¾ªç¯
    
    for iteration in range(max_iterations):
        # æŸ¥æ‰¾æ‰€æœ‰å¯è§çš„ Previous Comments æŒ‰é’®ï¼ˆåŒ…æ‹¬åµŒå¥—çš„ï¼‰
        all_previous_buttons = await page.locator('a:has-text("Previous Comments")').all()
        
        if not all_previous_buttons:
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„é€‰æ‹©å™¨
            all_previous_buttons = await page.locator(SELECTORS['PREVIOUS_COMMENTS_BUTTON']).all()
        
        if not all_previous_buttons:
            print(f"  ç¬¬ {iteration + 1} è½®ï¼šæ²¡æœ‰æ‰¾åˆ°æ›´å¤š Previous Comments æŒ‰é’®")
            break
        
        # è¿‡æ»¤å‡ºå¯è§çš„æŒ‰é’®
        visible_buttons = []
        for button in all_previous_buttons:
            try:
                if await button.is_visible():
                    visible_buttons.append(button)
            except:
                continue
        
        if not visible_buttons:
            print(f"  ç¬¬ {iteration + 1} è½®ï¼šæ²¡æœ‰å¯è§çš„ Previous Comments æŒ‰é’®")
            break
        
        print(f"  ç¬¬ {iteration + 1} è½®ï¼šæ‰¾åˆ° {len(visible_buttons)} ä¸ª Previous Comments æŒ‰é’®")
        
        # ç‚¹å‡»æ‰€æœ‰å¯è§çš„æŒ‰é’®
        buttons_clicked = 0
        for i, button in enumerate(visible_buttons):
            try:
                print(f"    ç‚¹å‡»ç¬¬ {i+1} ä¸ª Previous Comments æŒ‰é’®...")
                await button.scroll_into_view_if_needed()
                await page.wait_for_timeout(500)
                await button.click()
                buttons_clicked += 1
                total_loaded += 1
                
                # æ¯æ¬¡ç‚¹å‡»åç­‰å¾…å†…å®¹åŠ è½½
                await page.wait_for_timeout(1500)
                
            except Exception as e:
                print(f"    ç‚¹å‡»ç¬¬ {i+1} ä¸ªæŒ‰é’®å¤±è´¥: {e}")
                continue
        
        if buttons_clicked == 0:
            print(f"  ç¬¬ {iteration + 1} è½®ï¼šæ²¡æœ‰æˆåŠŸç‚¹å‡»ä»»ä½•æŒ‰é’®ï¼Œç»“æŸåŠ è½½")
            break
        
        print(f"  ç¬¬ {iteration + 1} è½®ï¼šæˆåŠŸç‚¹å‡»äº† {buttons_clicked} ä¸ªæŒ‰é’®")
        
        # ç­‰å¾…é¡µé¢ç¨³å®š
        await page.wait_for_load_state('networkidle', timeout=10000)
        await page.wait_for_timeout(config.WAIT_TIME)
    
    return total_loaded


async def expand_remaining_more_links(page, config, max_iterations=3):
    """
    å±•å¼€å‰©ä½™çš„Moreé“¾æ¥ï¼ˆç”¨äºPrevious CommentsåŠ è½½åçš„é¢å¤–å¤„ç†ï¼‰
    """
    expand_count = 0
    
    for iteration in range(max_iterations):
        try:
            # æŸ¥æ‰¾Moreé“¾æ¥
            more_links = []
            
            primary_links = await page.locator(SELECTORS['EXPAND_MORE_LINKS']).all()
            more_links.extend(primary_links)
            
            if not more_links:
                fallback_links = await page.locator(SELECTORS['EXPAND_LINKS_FALLBACK']).all()
                more_links.extend(fallback_links)
            
            if not more_links:
                break
                
            print(f"    æ‰¾åˆ° {len(more_links)} ä¸ªMoreé“¾æ¥")
            
            links_clicked = 0
            for i, link in enumerate(more_links):
                try:
                    if await link.is_visible():
                        await link.scroll_into_view_if_needed()
                        await page.wait_for_timeout(500)
                        await link.click(force=True)
                        links_clicked += 1
                        expand_count += 1
                        await page.wait_for_timeout(1000)
                except Exception as e:
                    continue
            
            if links_clicked == 0:
                break
                
            await page.wait_for_timeout(config.WAIT_TIME)
            
        except Exception as e:
            print(f"    å±•å¼€å‰©ä½™Moreé“¾æ¥æ—¶å‡ºé”™: {e}")
            break
    
    return expand_count


async def scroll_and_discover_comments(page, config):
    """
    é€šè¿‡é¡µé¢æ»šåŠ¨å’Œè§†è§’è°ƒæ•´æ¥å‘ç°éšè—çš„è¯„è®º
    """
    print("  ğŸ” æ‰§è¡Œé¡µé¢æ»šåŠ¨å’Œè§†è§’è°ƒæ•´ä»¥å‘ç°éšè—è¯„è®º...")
    
    try:
        # é¦–å…ˆæ»šåŠ¨åˆ°è¯„è®ºåŒºåŸŸ
        await page.locator('#sidebar-comments-region').scroll_into_view_if_needed()
        await page.wait_for_timeout(1000)
        
        # 1. å‘ä¸‹ç¼“æ…¢æ»šåŠ¨ï¼Œè§¦å‘æ‡’åŠ è½½
        print("    ğŸ“œ æ‰§è¡Œç¼“æ…¢æ»šåŠ¨ä»¥è§¦å‘æ‡’åŠ è½½...")
        for i in range(3):
            await page.evaluate("window.scrollBy(0, 300)")
            await page.wait_for_timeout(1500)
            
        # 2. æ»šåŠ¨åˆ°è¯„è®ºåŒºåŸŸåº•éƒ¨
        print("    â¬‡ï¸ æ»šåŠ¨åˆ°è¯„è®ºåŒºåŸŸåº•éƒ¨...")
        await page.evaluate("""
            const commentRegion = document.querySelector('#sidebar-comments-region');
            if (commentRegion) {
                commentRegion.scrollTop = commentRegion.scrollHeight;
            }
        """)
        await page.wait_for_timeout(2000)
        
        # 3. å›åˆ°è¯„è®ºåŒºåŸŸé¡¶éƒ¨
        print("    â¬†ï¸ å›åˆ°è¯„è®ºåŒºåŸŸé¡¶éƒ¨...")
        await page.evaluate("""
            const commentRegion = document.querySelector('#sidebar-comments-region');
            if (commentRegion) {
                commentRegion.scrollTop = 0;
            }
        """)
        await page.wait_for_timeout(1000)
        
        # 4. å°è¯•è°ƒæ•´é¡µé¢ç¼©æ”¾æ¯”ä¾‹
        print("    ğŸ” è°ƒæ•´é¡µé¢ç¼©æ”¾æ¯”ä¾‹...")
        # å…ˆç¼©å°åˆ°90%æŸ¥çœ‹æ›´å¤šå†…å®¹
        await page.evaluate("document.body.style.zoom = '0.9'")
        await page.wait_for_timeout(1000)
        
        # ç„¶åæ¢å¤æ­£å¸¸å¤§å°
        await page.evaluate("document.body.style.zoom = '1.0'")
        await page.wait_for_timeout(1000)
        
        print("    âœ… é¡µé¢æ»šåŠ¨å’Œè§†è§’è°ƒæ•´å®Œæˆ")
        
    except Exception as e:
        print(f"    âš ï¸ é¡µé¢æ»šåŠ¨å’Œè§†è§’è°ƒæ•´æ—¶å‡ºé”™: {e}")


async def load_all_comments(page, config):
    """
    å¢å¼ºçš„åŒå¾ªç¯åŠ è½½ç­–ç•¥
    Phase 0: é¡µé¢æ»šåŠ¨å’Œè§†è§’è°ƒæ•´
    Phase 1: å¾ªç¯ç‚¹å‡»"Previous Comments"ç›´åˆ°å…¨éƒ¨åŠ è½½
    Phase 2: å¾ªç¯ç‚¹å‡»æ‰€æœ‰"more"é“¾æ¥ç›´åˆ°å…¨éƒ¨å±•å¼€
    """
    print("å¼€å§‹åŠ è½½æ‰€æœ‰è¯„è®º...")
    
    # Phase 0: é¡µé¢æ»šåŠ¨å’Œè§†è§’è°ƒæ•´ (æ–°å¢)
    print("Phase 0: é¡µé¢æ»šåŠ¨å’Œè§†è§’è°ƒæ•´...")
    await scroll_and_discover_comments(page, config)
    
    # é‡æ–°è¿›è¡Œè°ƒè¯•åˆ†æï¼ˆæ»šåŠ¨åå¯èƒ½å‘ç°æ–°å†…å®¹ï¼‰
    await debug_page_structure(page)
    
    # Phase 1: åŠ è½½æ‰€æœ‰å±‚çº§çš„ Previous Comments
    print("Phase 1: åŠ è½½æ‰€æœ‰å±‚çº§çš„ Previous Comments...")
    
    total_previous_loaded = await load_all_previous_comments(page, config)
    print(f"  Phase 1 å®Œæˆ: æ€»å…±åŠ è½½äº† {total_previous_loaded} ä¸ª Previous Comments")
    
    # Phase 2: å±•å¼€æ‰€æœ‰æŠ˜å çš„è¯„è®ºå†…å®¹ï¼ˆMore é“¾æ¥ï¼‰
    print("Phase 2: å±•å¼€æ‰€æœ‰æŠ˜å çš„è¯„è®ºå†…å®¹...")
    expand_count = 0
    max_iterations = 8  # é™åˆ¶æœ€å¤§è¿­ä»£æ¬¡æ•°é˜²æ­¢æ— é™å¾ªç¯
    iteration = 0
    
    # æ— é™å¾ªç¯æ£€æµ‹å˜é‡
    previous_link_count = 0
    no_change_count = 0  # è¿ç»­æ— å˜åŒ–æ¬¡æ•°
    
    while iteration < max_iterations:
        try:
            # ä½¿ç”¨æ›´ç²¾ç¡®çš„é€‰æ‹©å™¨æŸ¥æ‰¾ More é“¾æ¥
            more_links = []
            
            # å°è¯•ä¸»è¦çš„ More é“¾æ¥é€‰æ‹©å™¨
            primary_links = await page.locator(SELECTORS['EXPAND_MORE_LINKS']).all()
            more_links.extend(primary_links)
            
            # å¦‚æœä¸»è¦é€‰æ‹©å™¨æ²¡æ‰¾åˆ°ï¼Œå°è¯•å¤‡é€‰é€‰æ‹©å™¨
            if not more_links:
                fallback_links = await page.locator(SELECTORS['EXPAND_LINKS_FALLBACK']).all()
                more_links.extend(fallback_links)
            
            if not more_links:
                print(f"  æ²¡æœ‰æ‰¾åˆ°æ›´å¤šæŠ˜å å†…å®¹ï¼Œå…±å±•å¼€äº† {expand_count} é¡¹")
                break
                
            current_link_count = len(more_links)
            print(f"  æ‰¾åˆ° {current_link_count} ä¸ªæŠ˜å å†…å®¹")
            
            # æ— é™å¾ªç¯æ£€æµ‹ï¼šå¦‚æœé“¾æ¥æ•°é‡æ²¡æœ‰å˜åŒ–ï¼Œå¯èƒ½é™·å…¥å¾ªç¯
            if current_link_count == previous_link_count:
                no_change_count += 1
                print(f"  âš ï¸ æ£€æµ‹åˆ°é“¾æ¥æ•°é‡æœªå˜åŒ–ï¼ˆè¿ç»­ {no_change_count} æ¬¡ï¼‰")
                if no_change_count >= 3:  # è¿ç»­3æ¬¡æ— å˜åŒ–å°±åœæ­¢
                    print(f"  ğŸ›‘ æ£€æµ‹åˆ°å¯èƒ½çš„æ— é™å¾ªç¯ï¼Œåœæ­¢Moreé“¾æ¥å±•å¼€")
                    break
            else:
                no_change_count = 0  # é‡ç½®è®¡æ•°å™¨
                
            previous_link_count = current_link_count
            
            # é€ä¸ªç‚¹å‡»å±•å¼€é“¾æ¥
            links_clicked = 0
            for i, link in enumerate(more_links):
                try:
                    # æ£€æŸ¥é“¾æ¥æ˜¯å¦å¯è§ä¸”æ–‡æœ¬ç¡®å®æ˜¯"more"
                    if await link.is_visible():
                        link_text = await link.text_content()
                        if not link_text or "more" not in link_text.lower():
                            print(f"    âš ï¸ ç¬¬ {i+1} ä¸ªé“¾æ¥æ–‡æœ¬ä¸åŒ¹é… ('{link_text}')ï¼Œè·³è¿‡")
                            continue
                            
                        print(f"    å‡†å¤‡ç‚¹å‡»ç¬¬ {i+1} ä¸ª More é“¾æ¥...")
                        
                        # æ»šåŠ¨åˆ°å…ƒç´ 
                        await link.scroll_into_view_if_needed()
                        await page.wait_for_timeout(1000)
                        
                        # å°è¯•å¤šç§ç‚¹å‡»æ–¹å¼
                        click_success = False
                        
                        # æ–¹æ³•1: æ™®é€šç‚¹å‡»
                        try:
                            await link.click(timeout=3000, force=True)
                            click_success = True
                            print(f"    âœ… æ–¹æ³•1æˆåŠŸç‚¹å‡»ç¬¬ {i+1} ä¸ª More é“¾æ¥")
                        except Exception:
                            pass
                        
                        # æ–¹æ³•2: JavaScript ç‚¹å‡»
                        if not click_success:
                            try:
                                await link.evaluate("element => element.click()")
                                click_success = True
                                print(f"    âœ… æ–¹æ³•2æˆåŠŸç‚¹å‡»ç¬¬ {i+1} ä¸ª More é“¾æ¥")
                            except Exception:
                                pass
                        
                        # æ–¹æ³•3: è§¦å‘äº‹ä»¶
                        if not click_success:
                            try:
                                await link.dispatch_event('click')
                                click_success = True
                                print(f"    âœ… æ–¹æ³•3æˆåŠŸç‚¹å‡»ç¬¬ {i+1} ä¸ª More é“¾æ¥")
                            except Exception:
                                pass
                        
                        if click_success:
                            links_clicked += 1
                            expand_count += 1
                            # ç­‰å¾…å†…å®¹å±•å¼€
                            await page.wait_for_timeout(1500)
                        else:
                            print(f"    âŒ æ‰€æœ‰æ–¹æ³•éƒ½æ— æ³•ç‚¹å‡»ç¬¬ {i+1} ä¸ª More é“¾æ¥")
                            
                    else:
                        print(f"    âš ï¸ ç¬¬ {i+1} ä¸ªé“¾æ¥ä¸å¯è§ï¼Œè·³è¿‡")
                        
                except Exception as e:
                    print(f"    âŒ å¤„ç†ç¬¬ {i+1} ä¸ª More é“¾æ¥æ—¶å‡ºé”™: {str(e)[:100]}...")
                    continue
            
            if links_clicked == 0:
                print(f"  æœ¬è½®æ²¡æœ‰æˆåŠŸç‚¹å‡»ä»»ä½•é“¾æ¥ï¼Œç»“æŸå±•å¼€")
                break
                
            print(f"  æœ¬è½®æˆåŠŸå±•å¼€ {links_clicked} ä¸ªæŠ˜å å†…å®¹")
            
            # ç­‰å¾…é¡µé¢ç¨³å®š
            await page.wait_for_timeout(config.WAIT_TIME)
            
            iteration += 1
            
            # æ—©æœŸé€€å‡ºæ£€æŸ¥ï¼šå¦‚æœè¿­ä»£æ¬¡æ•°è¶…è¿‡é™åˆ¶
            if iteration >= max_iterations:
                print(f"  ğŸ›‘ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° {max_iterations}ï¼Œåœæ­¢å±•å¼€é˜²æ­¢æ— é™å¾ªç¯")
                break
            
        except Exception as e:
            print(f"  å±•å¼€æŠ˜å å†…å®¹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            break
    
    print(f"è¯„è®ºåŠ è½½å®Œæˆï¼å…±å±•å¼€äº† {expand_count} é¡¹æŠ˜å å†…å®¹")
    
    # Phase 3: å±•å¼€Moreé“¾æ¥åï¼Œé‡æ–°æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„Previous Commentså‡ºç°
    print("Phase 3: æ£€æŸ¥å±•å¼€åæ˜¯å¦æœ‰æ–°çš„ Previous Comments...")
    additional_previous = await load_all_previous_comments(page, config)
    if additional_previous > 0:
        print(f"  å‘ç°å¹¶åŠ è½½äº†é¢å¤–çš„ {additional_previous} ä¸ª Previous Comments")
        
        # å¦‚æœåŠ è½½äº†æ–°çš„Previous Commentsï¼Œå¯èƒ½éœ€è¦é‡æ–°å±•å¼€Moreé“¾æ¥
        print("  é‡æ–°æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„Moreé“¾æ¥éœ€è¦å±•å¼€...")
        additional_expand = await expand_remaining_more_links(page, config, max_iterations=3)
        print(f"  é¢å¤–å±•å¼€äº† {additional_expand} é¡¹å†…å®¹")
    else:
        print("  æ²¡æœ‰å‘ç°æ–°çš„ Previous Comments")
    
    # Phase 4: æœ€ç»ˆå‘ç°é˜¶æ®µ - å†æ¬¡æ»šåŠ¨å’Œæœç´¢
    print("Phase 4: æœ€ç»ˆå‘ç°é˜¶æ®µ - å†æ¬¡æ»šåŠ¨å’Œæœç´¢...")
    await scroll_and_discover_comments(page, config)
    
    # æœ€ç»ˆæ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªå‘ç°çš„Previous Comments
    final_previous = await load_all_previous_comments(page, config)
    if final_previous > 0:
        print(f"  æœ€ç»ˆå‘ç°äº†é¢å¤–çš„ {final_previous} ä¸ª Previous Comments")
        # å†æ¬¡å±•å¼€å¯èƒ½çš„Moreé“¾æ¥
        final_expand = await expand_remaining_more_links(page, config, max_iterations=2)
        print(f"  æœ€ç»ˆé¢å¤–å±•å¼€äº† {final_expand} é¡¹å†…å®¹")
    else:
        print("  æœ€ç»ˆæ£€æŸ¥ï¼šæ²¡æœ‰å‘ç°æ›´å¤šPrevious Comments")


async def final_comment_verification(page, extracted_count):
    """
    æœ€ç»ˆéªŒè¯è¯„è®ºæå–çš„å®Œæ•´æ€§
    """
    try:
        expected_count = await get_expected_comment_count(page)
        if expected_count:
            if extracted_count < expected_count:
                shortage = expected_count - extracted_count
                print(f"âš ï¸ è¯„è®ºæå–å¯èƒ½ä¸å®Œæ•´:")
                print(f"   æœŸæœ›: {expected_count} æ¡")
                print(f"   å®é™…: {extracted_count} æ¡")  
                print(f"   ç¼ºå°‘: {shortage} æ¡")
                print(f"ğŸ’¡ å»ºè®®: å¯èƒ½éœ€è¦æ‰‹åŠ¨æ£€æŸ¥é¡µé¢æ˜¯å¦æœ‰æœªå±•å¼€çš„è¯„è®ºåŒºåŸŸ")
            elif extracted_count >= expected_count:
                print(f"âœ… è¯„è®ºæå–å®Œæ•´: {extracted_count}/{expected_count}")
            else:
                print(f"ğŸ“Š è¯„è®ºæå–ç»Ÿè®¡: {extracted_count} æ¡ (æœŸæœ›: {expected_count})")
    except Exception as e:
        print(f"éªŒè¯è¿‡ç¨‹å‡ºé”™: {e}")


async def extract_post_content(page) -> Dict[str, Any]:
    """
    æå–ä¸»å¸–å†…å®¹
    Returns: Dict - ä¸»å¸–æ•°æ®
    """
    print("å¼€å§‹æå–ä¸»å¸–å†…å®¹...")
    
    post_data = {
        'title': '',
        'content': '',
        'author': '',
        'timestamp': '',
        'url': page.url
    }
    
    try:
        # å°è¯•æå–å¸–å­æ ‡é¢˜ - ä½¿ç”¨æ›´ç²¾ç¡®çš„é€‰æ‹©å™¨é¿å…æ··æ·†
        title_selectors = [
            '#detail-layout > div.detail-layout-content-wrapper > div.detail-layout-title',
            '.detail-layout-title',
            '#detail-layout h1',
            '.post-title',
            '.article-title', 
            'h1',
            '[data-testid="post-title"]'
        ]
        
        for selector in title_selectors:
            try:
                title_element = page.locator(selector).first
                if await title_element.count() > 0:
                    post_data['title'] = await title_element.text_content()
                    print(f"âœ… æ‰¾åˆ°æ ‡é¢˜: {post_data['title'][:50]}...")
                    break
            except:
                continue
        
        # å°è¯•æå–å¸–å­å†…å®¹ - ä½¿ç”¨ç”¨æˆ·æä¾›çš„å‡†ç¡®é€‰æ‹©å™¨
        content_selectors = [
            '#detail-layout > div.detail-layout-content-wrapper > div.detail-layout-description.mighty-wysiwyg-content.mighty-max-content-width.fr-view',
            '.detail-layout-description.mighty-wysiwyg-content',
            '.detail-layout-description',
            '.mighty-wysiwyg-content',
            '.post-content .content',
            '.post-content',
            '.post-body .content',
            '.post-body',
            '[data-testid="post-content"]',
            '.main-post .content',
            '.content',
            '.main-content',
            '[class*="content"]'
        ]
        
        for selector in content_selectors:
            try:
                content_element = page.locator(selector).first
                if await content_element.count() > 0:
                    content_html = await content_element.inner_html()
                    if content_html and len(content_html.strip()) > 20:  # ç¡®ä¿ä¸æ˜¯ç©ºå†…å®¹
                        post_data['content'] = content_html.strip()
                        print(f"âœ… æ‰¾åˆ°å†…å®¹: {post_data['content'][:100]}...")
                        break
            except:
                continue
        
        # å°è¯•æå–ä½œè€…ä¿¡æ¯
        author_selectors = [
            '.post-author',
            '.author-name',
            '.user-name',
            '[data-testid="author"]'
        ]
        
        for selector in author_selectors:
            try:
                author_element = page.locator(selector).first
                if await author_element.count() > 0:
                    post_data['author'] = await author_element.text_content()
                    print(f"âœ… æ‰¾åˆ°ä½œè€…: {post_data['author']}")
                    break
            except:
                continue
        
        # å°è¯•æå–å‘å¸ƒæ—¶é—´
        time_selectors = [
            '.post-time',
            '.timestamp',
            '.published-date',
            'time'
        ]
        
        for selector in time_selectors:
            try:
                time_element = page.locator(selector).first
                if await time_element.count() > 0:
                    post_data['timestamp'] = await time_element.text_content()
                    print(f"âœ… æ‰¾åˆ°æ—¶é—´: {post_data['timestamp']}")
                    break
            except:
                continue
        
        return post_data
        
    except Exception as e:
        print(f"âŒ æå–ä¸»å¸–å†…å®¹æ—¶å‡ºé”™: {e}")
        return post_data


async def extract_comments(page) -> List[Dict[str, Any]]:
    """
    æå–è¯„è®ºæ•°æ®ï¼Œä¿æŒæ­£ç¡®çš„å±‚çº§ç»“æ„
    Returns: List[Dict] - è¯„è®ºæ•°æ®ç»“æ„ï¼ŒåªåŒ…å«æ ¹è¯„è®ºï¼Œå›å¤åµŒå¥—åœ¨å†…
    """
    print("å¼€å§‹æå–è¯„è®ºæ•°æ®...")
    
    try:
        # å®šä½è¯„è®ºå®¹å™¨
        container = page.locator('#sidebar-comments-region')
        
        if not await container.is_visible():
            print("âŒ æœªæ‰¾åˆ°è¯„è®ºåŒºå®¹å™¨")
            return []
        
        # ä½¿ç”¨æ›´ç²¾ç¡®çš„æ–¹æ³•æ¥æŸ¥æ‰¾æ ¹çº§è¯„è®º
        # é¦–å…ˆå°è¯•ç›´æ¥å®šä½æ ¹çº§è¯„è®º
        root_comment_items = await container.locator('> div > div.comments-region > ul > li').all()
        
        if not root_comment_items:
            # å¤‡ç”¨æ–¹æ³•ï¼šæŸ¥æ‰¾æ‰€æœ‰ liï¼Œä½†è¦è¿‡æ»¤å‡ºæ ¹çº§è¯„è®º
            all_items = await container.locator('li').all()
            print(f"æ‰¾åˆ° {len(all_items)} ä¸ªæ€»è¯„è®ºé¡¹ï¼Œå¼€å§‹è¿‡æ»¤æ ¹çº§è¯„è®º...")
            
            # è¿‡æ»¤æ ¹çº§è¯„è®ºï¼šæ£€æŸ¥æ¯ä¸ª li æ˜¯å¦æœ‰åµŒå¥—çš„ ulï¼ˆè¯´æ˜å®ƒæœ‰å›å¤ï¼‰
            # æˆ–è€…æ£€æŸ¥å®ƒæ˜¯å¦åœ¨å¦ä¸€ä¸ª li å†…éƒ¨ï¼ˆè¯´æ˜å®ƒæ˜¯å›å¤ï¼‰
            root_comment_items = []
            for item in all_items:
                try:
                    # æ£€æŸ¥è¿™ä¸ªè¯„è®ºæ˜¯å¦åœ¨å¦ä¸€ä¸ª li çš„ ul å†…éƒ¨ï¼ˆå³æ˜¯å›å¤ï¼‰
                    parent_li = item.locator('xpath=ancestor::li[1]')  
                    if await parent_li.count() == 0:  # æ²¡æœ‰çˆ¶çº§ liï¼Œè¯´æ˜æ˜¯æ ¹è¯„è®º
                        root_comment_items.append(item)
                except:
                    # å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œä¿é™©èµ·è§åŠ å…¥åˆ°æ ¹è¯„è®ºä¸­
                    root_comment_items.append(item)
            
            print(f"è¿‡æ»¤åå¾—åˆ° {len(root_comment_items)} ä¸ªæ ¹çº§è¯„è®º")
        
        print(f"å‡†å¤‡å¤„ç† {len(root_comment_items)} ä¸ªè¯„è®ºé¡¹")
        
        root_comments = []
        
        for i, item in enumerate(root_comment_items):
            try:
                print(f"  å¤„ç†è¯„è®º {i+1}...")
                comment_data = await extract_single_comment_with_replies(item)
                if comment_data and comment_data.get('text', '').strip():
                    root_comments.append(comment_data)
                    print(f"    âœ… è¯„è®º {i+1} å¤„ç†å®Œæˆ")
                else:
                    print(f"    âš ï¸ è¯„è®º {i+1} å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡")
                    
            except Exception as e:
                print(f"    âŒ å¤„ç†è¯„è®º {i+1} æ—¶å‡ºé”™: {e}")
                continue
        
        print(f"âœ… æˆåŠŸæå– {len(root_comments)} æ¡æ ¹è¯„è®º")
        
        # è®¡ç®—æ€»è¯„è®ºæ•°ï¼ˆåŒ…æ‹¬æ‰€æœ‰åµŒå¥—å›å¤ï¼‰
        total_extracted_comments = count_all_comments_recursively(root_comments)
        print(f"ğŸ“Š æ€»è¯„è®ºæ•°ç»Ÿè®¡: æ ¹è¯„è®º {len(root_comments)} æ¡, æ€»è®¡ {total_extracted_comments} æ¡ (åŒ…æ‹¬æ‰€æœ‰å›å¤)")
        
        # æœ€ç»ˆéªŒè¯ï¼šæ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœŸæœ›æ•°é‡
        await final_comment_verification(page, total_extracted_comments)
        
        return root_comments
        
    except Exception as e:
        print(f"âŒ æå–è¯„è®ºæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return []


async def extract_single_comment_with_replies(item) -> Dict[str, Any]:
    """
    æå–å•ä¸ªè¯„è®ºåŠå…¶å›å¤çš„æ•°æ®
    """
    comment_data = {
        'text': '',
        'author': '',
        'timestamp': '',
        'replies': []
    }
    
    try:
        # æå–ä¸»è¯„è®ºæ–‡æœ¬ - åªæå–å½“å‰å±‚çº§çš„å†…å®¹ï¼Œä¸åŒ…æ‹¬å›å¤
        comment_body = item.locator('.comment-body').first
        if await comment_body.count() > 0:
            # è·å–è¯„è®ºHTMLï¼Œä¿ç•™æ ¼å¼ä¿¡æ¯
            comment_html = await comment_body.inner_html()
            comment_data['text'] = clean_comment_html(comment_html)
        
        # æå–ä½œè€…ä¿¡æ¯
        author_selectors = [
            '.comment-author',
            '.user-name', 
            '.author-name',
            '.comment-header .name'
        ]
        
        for selector in author_selectors:
            try:
                author_element = item.locator(selector).first
                if await author_element.count() > 0:
                    comment_data['author'] = await author_element.text_content()
                    break
            except:
                continue
        
        # æå–æ—¶é—´æˆ³
        time_selectors = [
            '.timestamp',
            '.comment-time',
            '.time-ago',
            'time'
        ]
        
        for selector in time_selectors:
            try:
                time_element = item.locator(selector).first
                if await time_element.count() > 0:
                    comment_data['timestamp'] = await time_element.text_content()
                    break
            except:
                continue
        
        # æå–å›å¤ - æŸ¥æ‰¾åµŒå¥—çš„ ul > li ç»“æ„
        try:
            replies_container = item.locator('ul li')  # ç›´æ¥å­çº§çš„å›å¤
            if await replies_container.count() > 0:
                reply_items = await replies_container.all()
                print(f"    æ‰¾åˆ° {len(reply_items)} ä¸ªå›å¤")
                
                for reply_item in reply_items:
                    reply_data = await extract_single_reply(reply_item)
                    if reply_data and reply_data.get('text', '').strip():
                        comment_data['replies'].append(reply_data)
        except Exception as e:
            print(f"    æå–å›å¤æ—¶å‡ºé”™: {e}")
        
        return comment_data
        
    except Exception as e:
        print(f"    æå–è¯„è®ºæ•°æ®æ—¶å‡ºé”™: {e}")
        return comment_data


async def extract_single_reply(item) -> Dict[str, Any]:
    """
    æå–å•ä¸ªå›å¤çš„æ•°æ®
    """
    reply_data = {
        'text': '',
        'author': '',
        'timestamp': '',
        'replies': []  # æ”¯æŒå¤šå±‚åµŒå¥—å›å¤
    }
    
    try:
        # æå–å›å¤æ–‡æœ¬
        reply_body = item.locator('.comment-body').first
        if await reply_body.count() > 0:
            reply_html = await reply_body.inner_html()
            reply_data['text'] = clean_comment_html(reply_html)
        
        # æå–ä½œè€…
        author_selectors = [
            '.comment-author',
            '.user-name',
            '.author-name'
        ]
        
        for selector in author_selectors:
            try:
                author_element = item.locator(selector).first
                if await author_element.count() > 0:
                    reply_data['author'] = await author_element.text_content()
                    break
            except:
                continue
        
        # æå–æ—¶é—´æˆ³
        time_selectors = [
            '.timestamp',
            '.comment-time', 
            '.time-ago',
            'time'
        ]
        
        for selector in time_selectors:
            try:
                time_element = item.locator(selector).first
                if await time_element.count() > 0:
                    reply_data['timestamp'] = await time_element.text_content()
                    break
            except:
                continue
        
        return reply_data
        
    except Exception as e:
        print(f"    æå–å›å¤æ•°æ®æ—¶å‡ºé”™: {e}")
        return reply_data


def count_all_comments_recursively(comments_list):
    """
    é€’å½’è®¡ç®—æ‰€æœ‰è¯„è®ºçš„æ€»æ•°ï¼ˆåŒ…æ‹¬åµŒå¥—å›å¤ï¼‰
    """
    total = 0
    for comment in comments_list:
        total += 1  # è®¡ç®—å½“å‰è¯„è®º
        if comment.get('replies'):
            total += count_all_comments_recursively(comment['replies'])  # é€’å½’è®¡ç®—å›å¤
    return total


def clean_comment_text(text: str) -> str:
    """
    æ¸…ç†è¯„è®ºæ–‡æœ¬ï¼Œç§»é™¤å¤šä½™çš„ç©ºç™½å’Œæ ¼å¼å­—ç¬¦
    """
    if not text:
        return ""
    
    # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    text = re.sub(r'\s+', ' ', text.strip())
    # ç§»é™¤å¯èƒ½çš„ç³»ç»Ÿæ–‡æœ¬
    text = re.sub(r'(Reply|å›å¤|åˆ é™¤|Delete|ç¼–è¾‘|Edit)', '', text)
    return text.strip()


def clean_comment_html(html: str) -> str:
    """
    æ¸…ç†è¯„è®ºHTMLï¼Œä¿ç•™æ ¼å¼æ ‡ç­¾ä½†ç§»é™¤æ— ç”¨çš„ç³»ç»Ÿå…ƒç´ 
    """
    if not html:
        return ""
    
    # ç§»é™¤å¯èƒ½çš„ç³»ç»ŸæŒ‰é’®å’Œé“¾æ¥
    html = re.sub(r'<a[^>]*href[^>]*>[\s\S]*?(Reply|å›å¤|åˆ é™¤|Delete|ç¼–è¾‘|Edit|more|æ›´å¤š)[\s\S]*?</a>', '', html, flags=re.IGNORECASE)
    
    # ç§»é™¤ç©ºçš„æ®µè½å’Œdivæ ‡ç­¾
    html = re.sub(r'<(p|div)[^>]*>\s*</\1>', '', html, flags=re.IGNORECASE)
    
    # æ¸…ç†å¤šä½™çš„ç©ºç™½ä½†ä¿ç•™HTMLç»“æ„
    html = re.sub(r'\s+', ' ', html.strip())
    
    return html.strip()


async def extract_single_comment(item) -> Dict[str, Any]:
    """
    æå–å•ä¸ªè¯„è®ºçš„æ•°æ® (æ—§ç‰ˆæœ¬ï¼Œä¿æŒå…¼å®¹æ€§)
    """
    comment_data = {
        'text': '',
        'author': '',
        'timestamp': '',
        'replies': []
    }
    
    try:
        # æå–è¯„è®ºæ–‡æœ¬
        # å°è¯•å¤šç§å¯èƒ½çš„æ–‡æœ¬é€‰æ‹©å™¨
        text_selectors = [
            '.comment-text',
            '.comment-content', 
            '.content',
            'p',
            '.text'
        ]
        
        comment_text = ""
        for selector in text_selectors:
            try:
                text_elements = await item.locator(selector).all()
                if text_elements:
                    for element in text_elements:
                        text = await element.inner_text()
                        if text and text.strip():
                            comment_text += text.strip() + " "
                    if comment_text.strip():
                        break
            except:
                continue
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹å®šé€‰æ‹©å™¨ï¼Œè·å–æ•´ä¸ªitemçš„æ–‡æœ¬
        if not comment_text.strip():
            try:
                comment_text = await item.inner_text()
            except:
                comment_text = ""
        
        # æ¸…ç†æ–‡æœ¬
        comment_text = clean_text(comment_text)
        comment_data['text'] = comment_text
        
        # æå–ä½œè€…ä¿¡æ¯ (é€šå¸¸åœ¨é“¾æ¥æˆ–ç‰¹å®šclassä¸­)
        author_selectors = [
            '.author',
            '.username', 
            '.user',
            'a[href*="user"]',
            '.comment-author',
            'strong',
            'b'
        ]
        
        for selector in author_selectors:
            try:
                author_element = item.locator(selector).first
                if await author_element.is_visible():
                    author = await author_element.inner_text()
                    if author and author.strip():
                        comment_data['author'] = author.strip()
                        break
            except:
                continue
        
        # æå–æ—¶é—´æˆ³
        time_selectors = [
            '.timestamp',
            '.time',
            '.date',
            'time',
            '.comment-time',
            '[datetime]'
        ]
        
        for selector in time_selectors:
            try:
                time_element = item.locator(selector).first
                if await time_element.is_visible():
                    timestamp = await time_element.inner_text()
                    if timestamp and timestamp.strip():
                        comment_data['timestamp'] = timestamp.strip()
                        break
            except:
                continue
        
        # æå–å›å¤ (æŸ¥æ‰¾åµŒå¥—çš„liæˆ–ç‰¹å®šclass)
        try:
            # æŸ¥æ‰¾åµŒå¥—çš„è¯„è®ºåˆ—è¡¨
            nested_comments = await item.locator('ul li, ol li, .replies li, .nested-comments li').all()
            
            for nested_item in nested_comments:
                try:
                    nested_comment = await extract_single_comment(nested_item)
                    if nested_comment and nested_comment.get('text', '').strip():
                        comment_data['replies'].append(nested_comment)
                except:
                    continue
                    
        except:
            pass  # å¦‚æœæ²¡æœ‰å›å¤å°±è·³è¿‡
        
        return comment_data
        
    except Exception as e:
        print(f"    æå–å•ä¸ªè¯„è®ºæ•°æ®æ—¶å‡ºé”™: {e}")
        return comment_data


def clean_text(text: str) -> str:
    """
    æ¸…ç†å’Œæ ¼å¼åŒ–æ–‡æœ¬
    """
    if not text:
        return ""
    
    # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    text = re.sub(r'\s+', ' ', text)
    
    # ç§»é™¤é¦–å°¾ç©ºç™½
    text = text.strip()
    
    # ç§»é™¤ä¸€äº›å¸¸è§çš„æ— ç”¨æ–‡æœ¬
    unwanted_phrases = [
        'Reply',
        'Like',
        'Share', 
        'More',
        'Show more',
        'Show less',
        'å›å¤',
        'ç‚¹èµ',
        'åˆ†äº«',
        'æ›´å¤š'
    ]
    
    for phrase in unwanted_phrases:
        if text.strip() == phrase:
            return ""
    
    return text